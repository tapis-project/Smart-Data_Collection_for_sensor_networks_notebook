{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "from datetime import datetime, timedelta\n",
    "from tapipy.tapis import Tapis\n",
    "from random import gauss, randint\n",
    "from time import time_ns\n",
    "import random\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = getpass.getpass(prompt = \"Username: \", stream=None)\n",
    "password = getpass.getpass(prompt = \"Password: \", stream=None)\n",
    "vm_password = getpass.getpass(prompt = \"VM Password: \", stream=None)\n",
    "\n",
    "base_url = \"https://training.tapis.io\"\n",
    "\n",
    "client = Tapis(\n",
    "    base_url = base_url, \n",
    "    username = username,\n",
    "    password = password\n",
    ") \n",
    "\n",
    "#generate access token\n",
    "client.get_tokens()\n",
    "\n",
    "client.access_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_name = f\"{username}_{randint(0, 1000000)}\"\n",
    "\n",
    "project_id = f\"smart_data_workshop_project_{unique_name}\"\n",
    "site_id = f\"smart_data_workshop_site_{unique_name}\"\n",
    "inst_id = f\"smart_data_workshop_instrument_{unique_name}\"\n",
    "execution_system_id = f\"{unique_name}_tutorial_vm_execution_system\"\n",
    "storage_system_id = f\"{unique_name}_tutorial_vm_storage_system\"\n",
    "app_id = f\"{unique_name}_img_classifier\"\n",
    "trigger_channel_id = f\"{unique_name}_trigger_channel\"\n",
    "discord_channel_id = f\"{unique_name}_discord_channel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define and create project\n",
    "project = {\n",
    "    \"project_name\": project_id,\n",
    "    \"description\": f\"A smart data workshop project for user {username}\",\n",
    "    \"owner\": username,\n",
    "    \"pi\": username,\n",
    "    \"active\": True,\n",
    "    \"metadata\": {}\n",
    "}\n",
    "proj = client.streams.create_project(**project)\n",
    "proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define and create site\n",
    "site = {\n",
    "    \"project_id\": project_id,\n",
    "    \"request_body\": [{\n",
    "        \"site_name\": site_id,\n",
    "        \"site_id\": site_id,\n",
    "        \"description\": f\"A smart data workshop site for user {username}\",\n",
    "        \"latitude\": 19.89,\n",
    "        \"longitude\": 155.58,\n",
    "        \"elevation\": 10,\n",
    "        \"metadata\": {}\n",
    "    }]\n",
    "}\n",
    "site = client.streams.create_site(**site)\n",
    "site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define and create instrument\n",
    "instrument = {\n",
    "    \"project_id\": project_id,\n",
    "    \"site_id\": site_id,\n",
    "    \"request_body\": [{\n",
    "        \"inst_name\": inst_id,\n",
    "        \"inst_id\": inst_id,\n",
    "        \"inst_description\": f\"A smart data workshop instrument for user {username}\",\n",
    "        \"metadata\": {}\n",
    "    }]\n",
    "}\n",
    "inst = client.streams.create_instrument(**instrument)\n",
    "inst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define and create variables\n",
    "variables = {\n",
    "    \"project_id\": project_id,\n",
    "    \"site_id\": site_id,\n",
    "    \"inst_id\": inst_id,\n",
    "    \"request_body\": [{\n",
    "        \"var_name\": \"rainfall\",\n",
    "        \"var_id\": \"rainfall\",\n",
    "        \"units\": \"mm\",\n",
    "        \"shortname\": \"rf\",\n",
    "        \"metadata\": {}\n",
    "    },\n",
    "    {\n",
    "        \"var_name\": \"temperature\",\n",
    "        \"var_id\": \"temperature\",\n",
    "        \"units\": \"C\",\n",
    "        \"shortname\": \"temp\",\n",
    "        \"metadata\": {}\n",
    "    }]\n",
    "}\n",
    "streams_vars = client.streams.create_variable(**variables)\n",
    "streams_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write Measurements - For today \n",
    "variables = []\n",
    "#generate sensor records up to current time\n",
    "date = datetime.now() - timedelta(minutes = 10000)\n",
    "#generate 100 sensor records\n",
    "for i in range(0, 10000):\n",
    "    date = date + timedelta(minutes = 1)\n",
    "    date_s = date.isoformat() \n",
    "    variables.append({\"temperature\": randint(60, 89),\n",
    "                        \"rainfall\": randint(10, 200),\n",
    "                        \"datetime\": date_s\n",
    "                        })\n",
    "#write observations to measurements endpoint for our instrument\n",
    "result = client.streams.create_measurement(inst_id=inst_id, vars=variables)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download measurments as CSV\n",
    "result = client.streams.list_measurements(inst_id=inst_id,\n",
    "                                                    project_id=project_id, \n",
    "                                                    site_id=site_id,\n",
    "                                                    start_date='2021-01-01T00:00:00Z',\n",
    "                                                    end_date='2025-12-30T22:19:25Z',\n",
    "                                                    format='csv')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Measurements to Data Frame\n",
    "input = StringIO(str(result,'utf-8'))\n",
    "df = pd.read_csv(input)\n",
    "df['datetime']=pd.to_datetime(df['time'])\n",
    "df.set_index('datetime',inplace=True)\n",
    "df.pop('time')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Measurements in the DataFrame\n",
    "%matplotlib inline\n",
    "xfmt = md.DateFormatter('%H:%M:%S')\n",
    "df.plot(lw=1, colormap='jet', marker='.', \n",
    "        markersize=12, title='Timeseries Stream Output', rot=90).xaxis.set_major_formatter(xfmt)\n",
    "plt.tight_layout()\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('test.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to Tapis UI to view the created measurements https://ikewai.github.io/tapis_ui_streams_training_deploy/#/streams\n",
    "Login with your Tapis credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a storage system in Tapis so we can upload and download data from our server\n",
    "#NOTE you system id needs to be unique across Tapis- so add your last_name\n",
    "system = client.systems.createSystem(id=storage_system_id,\n",
    "            description=\"VM storage\",\n",
    "            host=\"129.114.17.159\",\n",
    "            systemType=\"LINUX\",\n",
    "            defaultAuthnMethod=\"PASSWORD\",\n",
    "            effectiveUserId=username,\n",
    "            rootDir=f\"/home/{username}/\",\n",
    "            canExec=False)\n",
    "system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add login credentials so Tapis can access the system - NORMALLY WE USED SSH KEYS but for this tutorial we will utliize the password auth\n",
    "#NOTE you need to update the systemId to what you used above\n",
    "\n",
    "client.systems.createUserCredential(systemId=storage_system_id,userName=username, password=vm_password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List the files in our home directory\n",
    "#NOTE the system id needs to be updated\n",
    "client.files.listFiles(systemId=storage_system_id, path=\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an Actor that we can pass to a channel to execute when a threshold triggers\n",
    "#NOTE update the name and the system_id\n",
    "my_actor = client.actors.create_actor(image=\"mcleanj/workshop_actor:0.0.12\",\n",
    "                                     name=\"Plot Streams Data-1\",\n",
    "                                     description=\"Actor that plots streams measurements.\",\n",
    "                                     default_environment={\"system_id\": storage_system_id, \"destination_path\": \"/\"})\n",
    "                                     \n",
    "                                     \n",
    "my_actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Channel to check for our Temperature exceeding 200- then execute an Actor to generate a plot and upload to our system\n",
    "#NOTE you have to change you channel id to a unique one - add your lastname\n",
    "channel = client.streams.create_channels(channel_id=trigger_channel_id, \n",
    "                            channel_name=trigger_channel_id, \n",
    "                            template_id=\"default_threshold\",\n",
    "                            triggers_with_actions=[\n",
    "                                {\"inst_ids\":[inst_id],\n",
    "                                \"condition\":{\"key\":inst_id+\".temperature\",\n",
    "                                              \"operator\":\">\", \n",
    "                                              \"val\":100},\n",
    "                                 \"action\":{\"method\": \"ACTOR\",\"actor_id\" : my_actor.id,\n",
    "                                           \"message\": f\"Instrument: {inst_id} exceeded Temperature threshold\"}}])\n",
    "channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write Measurements - to trigger our Channel\n",
    "\n",
    "#generate measurement\n",
    "date_s = datetime.now().isoformat()\n",
    "variables = [{\"temperature\": 230,\n",
    "                    \"rainfall\": 0,\n",
    "                    \"datetime\": date_s\n",
    "                    }]\n",
    "#write observations to measurements endpoint for our instrument\n",
    "result = client.streams.create_measurement(inst_id=inst_id, vars=variables)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List the Alerts issued on our Channel\n",
    "client.streams.list_alerts(channel_id=channel.channel_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch the latest alert and assign to a variable\n",
    "alert = client.streams.list_alerts(channel_id=channel.channel_id).alerts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch our Actor execution log\n",
    "client.actors.get_execution_logs(actor_id=alert.actor_id, \n",
    "                                 execution_id=alert.execution_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View our files on our VM - we should see the new plot file\n",
    "client.files.listFiles(systemId=storage_system_id, path=\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets download the file to view here in our notebook\n",
    "fileb =  client.files.getContents(systemId=storage_system_id, path='/plot_2022-04-28T02:17:55Z.png')\n",
    "with open(\"download.png\",\"wb\") as f:\n",
    "    f.write(fileb)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discord_channel = client.streams.create_channels(channel_id=discord_channel_id,\n",
    "                            channel_name=discord_channel_id, \n",
    "                            template_id=\"default_threshold\",\n",
    "                            triggers_with_actions=[\n",
    "                                {\"inst_ids\":[inst_id],\n",
    "                                 \"condition\":{\"key\":inst_id+\".rainfall\",\n",
    "                                              \"operator\":\">\", \n",
    "                                              \"val\":150},\n",
    "                                 \"action\":{\"method\":\"DISCORD\",\"webhook_url\" :\"https://discord.com/api/webhooks/969019400990646332/9ihkprgFimjrCDPOnWcxoJvLTJzYE24fOB7mPCYyRmAzUMeoHbgtRbCpC7b_dWnZoxUS\",\n",
    "                                           \"message\":\"My Instrument exceeded Rainfall threshold val ${ r.value}\"}}], _tapis_debug=True)\n",
    "discord_channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please join this discord link https://discord.gg/x8B5JZNm to view alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write Measurement - to trigger our Discord Channel\n",
    "#generate sensor record out of range\n",
    "date_s = datetime.now().isoformat()\n",
    "variables = [{\"temperature\": 80,\n",
    "                    \"rainfall\": 151,\n",
    "                    \"datetime\": date_s\n",
    "                    }]\n",
    "#write observations to measurements endpoint for our instrument\n",
    "result = client.streams.create_measurement(inst_id=inst_id, vars=variables)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a execution system in Tapis so we can upload and download data from our server\n",
    "#NOTE you system id needs to be unique across Tapis- so add your last_name\n",
    "\n",
    "system_config = {\n",
    "    \"id\": execution_system_id,\n",
    "    \"description\": \"System for testing jobs in training tenant\",\n",
    "    \"systemType\": \"LINUX\",\n",
    "    \"host\": \"129.114.17.159\",\n",
    "    \"effectiveUserId\": \"${apiUserId}\",\n",
    "    \"defaultAuthnMethod\": \"PASSWORD\",\n",
    "    \"rootDir\": \"/home\",\n",
    "    \"canExec\": True,\n",
    "    \"canRunBatch\": True,\n",
    "    \"jobRuntimes\": [\n",
    "        {\n",
    "            \"runtimeType\": \"DOCKER\",\n",
    "            \"version\": \"0.0.1d\"\n",
    "        },\n",
    "        {\n",
    "            \"runtimeType\": \"SINGULARITY\",\n",
    "            \"version\": \"0.0.1\"\n",
    "        }\n",
    "    ],\n",
    "    \"jobWorkingDir\": \"${apiUserId}/workdir\",\n",
    "    \"batchScheduler\": \"SLURM\",\n",
    "    \"batchLogicalQueues\": [\n",
    "        {\n",
    "            \"name\": \"tapisNormal\",\n",
    "            \"hpcQueueName\": \"debug\",\n",
    "            \"maxJobs\": 5,\n",
    "            \"maxJobsPerUser\": 1,\n",
    "            \"minNodeCount\": 1,\n",
    "            \"maxNodeCount\": 1,\n",
    "            \"minCoresPerNode\": 1,\n",
    "            \"maxCoresPerNode\": 4,\n",
    "            \"minMemoryMB\": 1,\n",
    "            \"maxMemoryMB\": 4096,\n",
    "            \"minMinutes\": 1,\n",
    "            \"maxMinutes\": 60\n",
    "        }\n",
    "    ],\n",
    "    \"batchDefaultLogicalQueue\": \"tapisNormal\"\n",
    "}\n",
    "system = client.systems.createSystem(**system_config)\n",
    "\n",
    "system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.systems.createUserCredential(systemId=execution_system_id,userName=username, password=vm_password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List the files in our home directory\n",
    "client.files.listFiles(systemId=execution_system_id, path=f\"/{username}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_config = {\n",
    "    \"id\": app_id,\n",
    "    \"version\": \"0.1\",\n",
    "    \"description\": \"An image classifier run via FORK using docker.\",\n",
    "    \"runtime\": \"DOCKER\",\n",
    "    \"jobType\": \"FORK\",\n",
    "    \"containerImage\": \"tapis/img-classify2:0.1\",\n",
    "    \"jobAttributes\": {\n",
    "        \"execSystemId\": execution_system_id,\n",
    "        \"execSystemExecDir\": \"${JobWorkingDir}/jobs/${JobUUID}\",\n",
    "        \"execSystemInputDir\": \"${JobWorkingDir}/jobs/${JobUUID}/data\",\n",
    "        \"execSystemOutputDir\": \"${JobWorkingDir}/jobs/${JobUUID}/output\",\n",
    "        \"parameterSet\": {\n",
    "           \"appArgs\": [\n",
    "             { \"name\": \"arg1\", \"arg\": \"--image_file\" },\n",
    "             { \"name\": \"inputFile\",\n",
    "               \"arg\": \"https://s3.amazonaws.com/cdn-origin-etr.akc.org/wp-content/uploads/2017/11/12231410/Labrador-Retriever-On-White-01.jpg\"\n",
    "             }\n",
    "           ],\n",
    "           \"archiveFilter\":\n",
    "            { \n",
    "              \"includeLaunchFiles\": True\n",
    "            }\n",
    "        },\n",
    "        \"memoryMB\": 2048,\n",
    "        \"nodeCount\": 1,\n",
    "        \"coresPerNode\": 4,\n",
    "        \"maxMinutes\": 10\n",
    "    }\n",
    "}\n",
    "app = client.apps.createAppVersion(**app_config)\n",
    "\n",
    "app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to Tapis UI to run the job https://ikewai.github.io/tapis_ui_streams_training_deploy/#/apps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
